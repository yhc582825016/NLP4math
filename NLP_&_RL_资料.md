## NLP Books & Blog
1. [The Transformer Family | Lil'Log (lilianweng.github.io)](https://lilianweng.github.io/posts/2020-04-07-the-transformer-family/)
2. [transformers/src/transformers/generation/utils.py at v4.31.0 · huggingface/transformers (github.com)](https://github.com/huggingface/transformers/blob/v4.31.0/src/transformers/generation/utils.py#L1160)
3. [如何生成文本：通过 Transformers 用不同的解码方法生成文本 (huggingface.co)](https://huggingface.co/blog/zh/how-to-generate)
4. [facebookresearch/llama: Inference code for LLaMA models (github.com)](https://github.com/facebookresearch/llama)
5. [Llama 2.pdf](https://yach-doc-shimo.zhiyinlou.com/uploader/f/qZzBMvVgYcAxQGNY.pdf?fileGuid=ZzkLVnx9bJTLNM3Q)
6. [大规模语言模型-从理论到实践.pdf](https://yach-doc-shimo.zhiyinlou.com/uploader/f/ppaYS5F2p8YmXDEJ.pdf?fileGuid=ZzkLVnx9bJTLNM3Q)
## RL Books & Blog
1. [Policy Gradient Algorithms | Lil'Log (lilianweng.github.io)](https://lilianweng.github.io/posts/2018-04-08-policy-gradient/)
2. [初探强化学习 (boyuai.com)](https://hrl.boyuai.com/chapter/1/%E5%88%9D%E6%8E%A2%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0)
3. [蘑菇书EasyRL (datawhalechina.github.io)](https://datawhalechina.github.io/easy-rl/#/)
4. [强化学习从入门到放弃 - lintao | LT Blog (taospirit.github.io)](https://taospirit.github.io/2019/04/15/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8/)
5. [RLbook2020.pdf (incompleteideas.net)](http://incompleteideas.net/book/RLbook2020.pdf)
6. [深度强化学习(中文版-彩色压缩).pdf (deepreinforcementlearningbook.org)](https://deepreinforcementlearningbook.org/assets/pdfs/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0(%E4%B8%AD%E6%96%87%E7%89%88-%E5%BD%A9%E8%89%B2%E5%8E%8B%E7%BC%A9).pdf)
7. [深度强化学习.pdf](https://yach-doc-shimo.zhiyinlou.com/uploader/f/fldCZmkaOn4zMfL5.pdf?fileGuid=ZzkLVnx9bJTLNM3Q)王树森
8. [report.pdf](https://yach-doc-shimo.zhiyinlou.com/uploader/f/QUAuKuiYIR0J1kAh.pdf?fileGuid=ZzkLVnx9bJTLNM3Q) TRPO
## papers
### Core Paper
* A Survey of Deep Learning for Mathematical Reasoning.
* Let’s Verify Step by Step
* Training Verifiers to Solve Math Word Problems
* Solving math word problems with process and outcome-based feedba
### Math & Reasoning
1. [Solving Math Word Problems via Cooperative Reasoning induced Language Models - ACL Anthology](https://aclanthology.org/2023.acl-long.245/)
2. [Towards Reasoning in Large Language Models: A Survey - ACL Anthology](https://aclanthology.org/2023.findings-acl.67/)
3. [A Survey of Deep Learning for Mathematical Reasoning - ACL Anthology](https://aclanthology.org/2023.acl-long.817/)
4. [Interpretable Math Word Problem Solution Generation via Step-by-step Planning - ACL Anthology](https://aclanthology.org/2023.acl-long.379/)
5. [Compositional Mathematical Encoding for Math Word Problems - ACL Anthology](https://aclanthology.org/2023.findings-acl.635/)
6. [Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models - ACL Anthology](https://aclanthology.org/2023.acl-long.147/)
7. [Reasoning with Language Model Prompting: A Survey - ACL Anthology](https://aclanthology.org/2023.acl-long.294/)
8. [GeoDRL: A Self-Learning Framework for Geometry Problem Solving using Reinforcement Learning in Deductive Reasoning - ACL Anthology](https://aclanthology.org/2023.findings-acl.850/)
9. [A Causal Framework to Quantify the Robustness of Mathematical Reasoning with Language Models - ACL Anthology](https://aclanthology.org/2023.acl-long.32/)
10. [Math Word Problem Solving by Generating Linguistic Variants of Problem Statements](https://aclanthology.org/2023.acl-srw.49.pdf)
11. [Making Language Models Better Reasoners with Step-Aware Verifier](https://aclanthology.org/2023.acl-long.291.pdf)
12. [ALERT: Adapting Language Models to Reasoning Tasks](https://aclanthology.org/2023.acl-long.60.pdf)
13. [Distilling Reasoning Capabilities into Smaller Language Models](https://aclanthology.org/2023.findings-acl.441.pdf)
14. [Guiding Mathematical Reasoning via Mastering Commonsense Formula Knowledge](https://dl.acm.org/doi/pdf/10.1145/3580305.3599375)
15. [SCALING RELATIONSHIP ON LEARNING MATHEMATICAL REASONING WITH LARGE LANGUAGE MODELS](https://arxiv.org/pdf/2308.01825.pdf)
16. [Discriminator-Guided Multi-step Reasoning with Language Models](https://arxiv.org/pdf/2305.14934.pdf)
17. [2304.01904.pdf (arxiv.org)](https://arxiv.org/pdf/2304.01904.pdf) refiner
18. [2203.14465.pdf (arxiv.org)](https://arxiv.org/pdf/2203.14465.pdf) star
19. [2307.12950.pdf (arxiv.org)](https://arxiv.org/pdf/2307.12950.pdf) rlcd
20. [2304.06767.pdf (arxiv.org)](https://arxiv.org/pdf/2304.06767.pdf) raft
21. [2212.08073.pdf (arxiv.org)](https://arxiv.org/pdf/2212.08073.pdf) rlaif
### Training method
1. [2306.17492.pdf (arxiv.org)](https://arxiv.org/pdf/2306.17492.pdf) PRO
2. [2305.18290.pdf (arxiv.org)](https://arxiv.org/pdf/2305.18290.pdf) DPO
3. [SATISTICAL REJECTION SAMPLING IMPROVES PREFERENCE OPTIMIZATION](https://arxiv.org/pdf/2309.06657.pdf) RSO
4. [https://promptpg.github.io/](https://promptpg.github.io/) promptpg
### Prompt Engineering
1. [arxiv.org/pdf/2304.12244.pdf](https://arxiv.org/pdf/2304.12244.pdf) wizardLM
2. [arxiv.org/pdf/2306.08568.pdf](https://arxiv.org/pdf/2306.08568.pdf) wizardcode
3. [2212.10560.pdf (arxiv.org)](https://arxiv.org/pdf/2212.10560.pdf) self instruct
4. [Stanford CRFM](https://crfm.stanford.edu/2023/03/13/alpaca.html) aipaca
5. [Vicuna](https://lmsys.org/blog/2023-03-30-vicuna/)
6. [2203.02155.pdf (arxiv.org)](https://arxiv.org/pdf/2203.02155.pdf) instruct gpt
7. [2305.14688.pdf (arxiv.org)](https://arxiv.org/pdf/2305.14688.pdf) ExpertPrompting
8. [2308.00436.pdf (arxiv.org)](https://arxiv.org/pdf/2308.00436.pdf) self check
9. [WizardMath](https://arxiv.org/pdf/2308.09583.pdf)
10. [MATHPROMPTER: MATHEMATICAL REASONING USING LARGE LANGUAGE MODELS](https://arxiv.org/pdf/2303.05398.pdf)
11. [Deductive Verification of Chain-of-Thought Reasoning](https://arxiv.org/pdf/2306.03872.pdf)
12. [Large Language Models are Better Reasoners with Self-Verification](https://arxiv.org/pdf/2212.09561.pdf)
13. [When Do Program-of-Thought Works for Reasoning?](https://arxiv.org/pdf/2308.15452.pdf)
14. [Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks](https://arxiv.org/pdf/2211.12588.pdf)
15. [Toolformer: Language Models Can Teach Themselves to Use Tools](https://arxiv.org/pdf/2302.04761.pdf)
16. [SOLVING CHALLENGING MATH WORD PROBLEMS USING GPT-4 CODE INTERPRETER WITH CODE-BASED SELF-VERIFICATION](https://arxiv.org/pdf/2308.07921.pdf)
17. [MAMMOTH: BUILDING MATH GENERALIST MODELS THROUGH HYBRID INSTRUCTION TUNING](https://arxiv.org/pdf/2309.05653.pdf%3E)
### RL paper
1. [OFFLINE RL FOR NATURAL LANGUAGE GENERATION WITH IMPLICIT LANGUAGE Q LEARNING](https://arxiv.org/pdf/2206.11871.pdf)
2. [OFFLINE REINFORCEMENT LEARNING WITH IMPLICIT Q-LEARNING](https://arxiv.org/pdf/2110.06169.pdf)
3. [2022.findings-naacl.18.pdf (aclanthology.org)](https://aclanthology.org/2022.findings-naacl.18.pdf)
4. [Reinforced Self-Training (ReST) for Language Modeling](https://arxiv.org/pdf/2308.08998.pdf)
### Eval
1. [AGIEval- A Human-Centric Benchmark for  Evaluating Foundation Models.pdf](https://yach-doc-shimo.zhiyinlou.com/uploader/f/JfH1US1U7VWUp6Zl.pdf?fileGuid=ZzkLVnx9bJTLNM3Q)
2. [C-EVAL- A Multi-Level Multi-Discipline Chinese  Evaluation Suite for Foundation Models.pdf](https://yach-doc-shimo.zhiyinlou.com/uploader/f/KeIS83FG3f6eWVdw.pdf?fileGuid=ZzkLVnx9bJTLNM3Q)
3. [2305.12474.pdf (arxiv.org)](https://arxiv.org/pdf/2305.12474.pdf) gaokao
4. [2304.10703.pdf (arxiv.org)](https://arxiv.org/pdf/2304.10703.pdf) receval
5. [A General Language Assistant as a Laboratory for Alignment](https://arxiv.org/pdf/2112.00861.pdf)
### Code RL
1. [PANGU-CODER2](https://arxiv.org/pdf/2307.14936.pdf)
2. [CodeRL: Mastering Code Generation through Pretrained Models and Deep Reinforcement Learning](https://arxiv.org/pdf/2207.01780.pdf)
3. [RLTF: Reinforcement Learning from Unit Test Feedback](https://arxiv.org/pdf/2307.04349.pdf)
4. [RepoCoder: Repository-Level Code Completion Through Iterative Retrieval and Generation](https://arxiv.org/pdf/2303.12570.pdf)
5. [Execution-based Code Generation using Deep Reinforcement Learning](https://arxiv.org/pdf/2301.13816.pdf)
6. [ReACC: A Retrieval-Augmented Code Completion Framework](https://arxiv.org/pdf/2203.07722.pdf)
### Rumer detect
1. [Multimodal Fusion with Recurrent Neural Networks for Rumor Detection on Microblogs](https://static.aminer.org/pdf/20170130/pdfs/mm/5wageac2urysmthm3f9ziqg4xksqlwth.pdf)
2. [Detection and visualization of misleading content on Twitter](https://cz5waila03cyo0tux1owpyofgoryroob.oss-cn-beijing.aliyuncs.com/20/B3/CA/20B3CA17A85A3B645D37106517CC6FB1.pdf)
3. [Interpretable Multimodal Misinformation Detection with Logic Reasoning](https://arxiv.org/pdf/2305.05964.pdf)
4. [Causal Intervention and Counterfactual Reasoning for Multi-modal Fake News Detection](https://aclanthology.org/2023.acl-long.37.pdf)
###  LLM training
1. [SCALING RELATIONSHIP ON LEARNING MATHEMATICAL REASONING WITH LARGE LANGUAGE MODEL](https://arxiv.org/pdf/2308.01825.pdf)
2. [JiuZhang: A Chinese Pre-trained Language Model for Mathematical Problem Understanding](https://arxiv.org/pdf/2206.06315.pdf)
* MOE
* [GLaM: Efficient Scaling of Language Models with Mixture-of-Experts](https://arxiv.org/pdf/2112.06905.pdf)
* [Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity](https://arxiv.org/pdf/2101.03961.pdf)
* [Modeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts](https://static.aminer.cn/upload/pdf/program/5b67b45517c44aac1c86084b_0.pdf)
* [GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding](https://arxiv.org/pdf/2006.16668.pdf)
* [OUTRAGEOUSLY LARGE NEURAL NETWORKS: THE SPARSELY-GATED MIXTURE-OF-EXPERTS LAYER](https://arxiv.org/pdf/1701.06538.pdf)
* [Go Wider Instead of Deeper](https://arxiv.org/pdf/2107.11817.pdf)
* [MoEBERT: from BERT to Mixture-of-Experts via Importance-Guided Adaptation](https://arxiv.org/pdf/2204.07675.pdf)
* [MATH Dataset](https://yach-doc-shimo.zhiyinlou.com/docs/ZzkLVnoKB4T4Vz3Q/)
* Leaderboard
1. [Open LLM Leaderboard - a Hugging Face Space by HuggingFaceH4](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)
2. [Alpaca Eval Leaderboard (tatsu-lab.github.io)](https://tatsu-lab.github.io/alpaca_eval/)
3. [Leaderboard | C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models (cevalbenchmark.com)](https://cevalbenchmark.com/static/model.html?method=ChatGLM2)
### Blogs
* [Language model resoning](https://zhuanlan.zhihu.com/p/607212335)
### Others
1. [Models - OpenAI API](https://platform.openai.com/docs/models/gpt-4)
