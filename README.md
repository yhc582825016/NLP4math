# NLP4math
自然语言处理和强化学习相关的资料
* NLP
1. [The Transformer Family | Lil'Log (lilianweng.github.io)](https://lilianweng.github.io/posts/2020-04-07-the-transformer-family/)
2. [transformers/src/transformers/generation/utils.py at v4.31.0 · huggingface/transformers (github.com)](https://github.com/huggingface/transformers/blob/v4.31.0/src/transformers/generation/utils.py#L1160)
3. [如何生成文本：通过 Transformers 用不同的解码方法生成文本 (huggingface.co)](https://huggingface.co/blog/zh/how-to-generate)
4. [facebookresearch/llama: Inference code for LLaMA models (github.com)](https://github.com/facebookresearch/llama)
5. [Llama 2.pdf](https://yach-doc-shimo.zhiyinlou.com/uploader/f/qZzBMvVgYcAxQGNY.pdf?fileGuid=ZzkLVnx9bJTLNM3Q)
* RL
1. [Policy Gradient Algorithms | Lil'Log (lilianweng.github.io)](https://lilianweng.github.io/posts/2018-04-08-policy-gradient/)
2. [初探强化学习 (boyuai.com)](https://hrl.boyuai.com/chapter/1/%E5%88%9D%E6%8E%A2%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0)
3. [蘑菇书EasyRL (datawhalechina.github.io)](https://datawhalechina.github.io/easy-rl/#/)
4. [强化学习从入门到放弃 - lintao | LT Blog (taospirit.github.io)](https://taospirit.github.io/2019/04/15/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8/)
5. [RLbook2020.pdf (incompleteideas.net)](http://incompleteideas.net/book/RLbook2020.pdf)
6. [深度强化学习.pdf](https://yach-doc-shimo.zhiyinlou.com/uploader/f/fldCZmkaOn4zMfL5.pdf?fileGuid=ZzkLVnx9bJTLNM3Q)王树森
7. [report.pdf](https://yach-doc-shimo.zhiyinlou.com/uploader/f/QUAuKuiYIR0J1kAh.pdf?fileGuid=ZzkLVnx9bJTLNM3Q) TRPO
* papers
* core paper
* [A Survey of Deep Learning for Mathematical Reasoning.pdf](https://yach-doc-shimo.zhiyinlou.com/uploader/f/P1JLAsAofE5FC1NS.pdf?fileGuid=ZzkLVnx9bJTLNM3Q)Math Dataset Survey
* [Let’s Verify Step by Step.pdf](https://yach-doc-shimo.zhiyinlou.com/uploader/f/fOqIghtOTHHmmLqy.pdf?fileGuid=ZzkLVnx9bJTLNM3Q)Openai Verify 23[Training Verifiers to Solve Math Word Problems.pdf](https://yach-doc-shimo.zhiyinlou.com/uploader/f/nS9XBPjupgCgOGXQ.pdf?fileGuid=ZzkLVnx9bJTLNM3Q)Openai Verify 21
* [Solving math word problems with processand outcome-based feedba.pdf](https://yach-doc-shimo.zhiyinlou.com/uploader/f/PwatAXkkamJlXk3j.pdf?fileGuid=ZzkLVnx9bJTLNM3Q) Deepmind Math RL
* math & reasoning
1. [Solving Math Word Problems via Cooperative Reasoning induced Language Models - ACL Anthology](https://aclanthology.org/2023.acl-long.245/)
2. [Towards Reasoning in Large Language Models: A Survey - ACL Anthology](https://aclanthology.org/2023.findings-acl.67/)
3. [A Survey of Deep Learning for Mathematical Reasoning - ACL Anthology](https://aclanthology.org/2023.acl-long.817/)
4. [Interpretable Math Word Problem Solution Generation via Step-by-step Planning - ACL Anthology](https://aclanthology.org/2023.acl-long.379/)
5. [Compositional Mathematical Encoding for Math Word Problems - ACL Anthology](https://aclanthology.org/2023.findings-acl.635/)
6. [Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models - ACL Anthology](https://aclanthology.org/2023.acl-long.147/)
7. [Reasoning with Language Model Prompting: A Survey - ACL Anthology](https://aclanthology.org/2023.acl-long.294/)
8. [GeoDRL: A Self-Learning Framework for Geometry Problem Solving using Reinforcement Learning in Deductive Reasoning - ACL Anthology](https://aclanthology.org/2023.findings-acl.850/)
9. [A Causal Framework to Quantify the Robustness of Mathematical Reasoning with Language Models - ACL Anthology](https://aclanthology.org/2023.acl-long.32/)
10. [Math Word Problem Solving by Generating Linguistic Variants of Problem Statements](https://aclanthology.org/2023.acl-srw.49.pdf)
11. [Making Language Models Better Reasoners with Step-Aware Verifier](https://aclanthology.org/2023.acl-long.291.pdf)
12. [ALERT: Adapting Language Models to Reasoning Tasks](https://aclanthology.org/2023.acl-long.60.pdf)
13. [Distilling Reasoning Capabilities into Smaller Language Models](https://aclanthology.org/2023.findings-acl.441.pdf)
14. [Guiding Mathematical Reasoning via Mastering Commonsense Formula Knowledge](https://dl.acm.org/doi/pdf/10.1145/3580305.3599375)
15. [2304.01904.pdf (arxiv.org)](https://arxiv.org/pdf/2304.01904.pdf) refiner
16. [2203.14465.pdf (arxiv.org)](https://arxiv.org/pdf/2203.14465.pdf) star
17. [2307.12950.pdf (arxiv.org)](https://arxiv.org/pdf/2307.12950.pdf) rlcd
18. [2304.06767.pdf (arxiv.org)](https://arxiv.org/pdf/2304.06767.pdf) raft
19. [2212.08073.pdf (arxiv.org)](https://arxiv.org/pdf/2212.08073.pdf) rlaif
* Training method
1. [2306.17492.pdf (arxiv.org)](https://arxiv.org/pdf/2306.17492.pdf) PRO
2. [2305.18290.pdf (arxiv.org)](https://arxiv.org/pdf/2305.18290.pdf) DPO
3. [https://promptpg.github.io/](https://promptpg.github.io/) promptpg
* **Instuct tuning**
1. [arxiv.org/pdf/2304.12244.pdf](https://arxiv.org/pdf/2304.12244.pdf) wizardLM
2. [arxiv.org/pdf/2306.08568.pdf](https://arxiv.org/pdf/2306.08568.pdf) wizardcode
3. [2212.10560.pdf (arxiv.org)](https://arxiv.org/pdf/2212.10560.pdf) self instruct
4. [Stanford CRFM](https://crfm.stanford.edu/2023/03/13/alpaca.html) aipaca
5. [Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90%* ChatGPT Quality | LMSYS Org](https://lmsys.org/blog/2023-03-30-vicuna/)
6. [2203.02155.pdf (arxiv.org)](https://arxiv.org/pdf/2203.02155.pdf) instruct gpt
7. [2305.14688.pdf (arxiv.org)](https://arxiv.org/pdf/2305.14688.pdf) ExpertPrompting
8. [2308.00436.pdf (arxiv.org)](https://arxiv.org/pdf/2308.00436.pdf) self check
9. [WizardMath](https://github.com/nlpxucan/WizardLM/tree/main/WizardMath)
10. [MATHPROMPTER: MATHEMATICAL REASONING USING LARGE LANGUAGE MODELS](https://arxiv.org/pdf/2303.05398.pdf)
* RL
1. [OFFLINE RL FOR NATURAL LANGUAGE GENERATION WITH IMPLICIT LANGUAGE Q LEARNING](https://arxiv.org/pdf/2206.11871.pdf)
2. [OFFLINE REINFORCEMENT LEARNING WITH IMPLICIT Q-LEARNING](https://OFFLINE REINFORCEMENT LEARNING WITH IMPLICIT Q-LEARNING)
3. [2022.findings-naacl.18.pdf (aclanthology.org)](https://aclanthology.org/2022.findings-naacl.18.pdf)
* **Eval**
1. [AGIEval- A Human-Centric Benchmark for  Evaluating Foundation Models.pdf](https://yach-doc-shimo.zhiyinlou.com/uploader/f/JfH1US1U7VWUp6Zl.pdf?fileGuid=ZzkLVnx9bJTLNM3Q)
2. [C-EVAL- A Multi-Level Multi-Discipline Chinese  Evaluation Suite for Foundation Models.pdf](https://yach-doc-shimo.zhiyinlou.com/uploader/f/KeIS83FG3f6eWVdw.pdf?fileGuid=ZzkLVnx9bJTLNM3Q)
3. [2305.12474.pdf (arxiv.org)](https://arxiv.org/pdf/2305.12474.pdf) gaokao
4. [2304.10703.pdf (arxiv.org)](https://arxiv.org/pdf/2304.10703.pdf) receval
5. [A General Language Assistant as a Laboratory for Alignment](https://A General Language Assistant as a Laboratory for Alignment)
* **Code RL**
1. [PANGU-CODER2](https://arxiv.org/pdf/2307.14936.pdf)
2. [CodeRL: Mastering Code Generation through Pretrained Models and Deep Reinforcement Learning](https://arxiv.org/pdf/2207.01780.pdf)
3. [RLTF: Reinforcement Learning from Unit Test Feedback](https://arxiv.org/pdf/2307.04349.pdf)
4. [RepoCoder: Repository-Level Code Completion Through Iterative Retrieval and Generation](https://arxiv.org/pdf/2303.12570.pdf)
5. [Execution-based Code Generation using Deep Reinforcement Learning](https://arxiv.org/pdf/2301.13816.pdf)
6. [ReACC: A Retrieval-Augmented Code Completion Framework](https://arxiv.org/pdf/2203.07722.pdf)
* Rumer detect
1. [Multimodal Fusion with Recurrent Neural Networks for Rumor Detection on Microblogs](https://static.aminer.org/pdf/20170130/pdfs/mm/5wageac2urysmthm3f9ziqg4xksqlwth.pdf)
2. [Detection and visualization of misleading content on Twitter](https://cz5waila03cyo0tux1owpyofgoryroob.oss-cn-beijing.aliyuncs.com/20/B3/CA/20B3CA17A85A3B645D37106517CC6FB1.pdf)
3. [Interpretable Multimodal Misinformation Detection with Logic Reasoning](https://arxiv.org/pdf/2305.05964.pdf)
4. [Causal Intervention and Counterfactual Reasoning for Multi-modal Fake News Detection](https://Causal Intervention and Counterfactual Reasoning for Multi-modal Fake News Detection)
* LLM training
1. [SCALING RELATIONSHIP ON LEARNING MATHEMATICAL REASONING WITH LARGE LANGUAGE MODEL](https://arxiv.org/pdf/2308.01825.pdf)
2. [JiuZhang: A Chinese Pre-trained Language Model for Mathematical Problem Understanding](https://arxiv.org/pdf/2206.06315.pdf)
* MOE
* [GLaM: Efficient Scaling of Language Models with Mixture-of-Experts](https://arxiv.org/pdf/2112.06905.pdf)
* [Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity](https://arxiv.org/pdf/2101.03961.pdf)
* [Modeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts](https://static.aminer.cn/upload/pdf/program/5b67b45517c44aac1c86084b_0.pdf)
* [GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding](https://arxiv.org/pdf/2006.16668.pdf)
* [OUTRAGEOUSLY LARGE NEURAL NETWORKS: THE SPARSELY-GATED MIXTURE-OF-EXPERTS LAYER](https://arxiv.org/pdf/1701.06538.pdf)
* [Go Wider Instead of Deeper](https://arxiv.org/pdf/2107.11817.pdf)
* [MoEBERT: from BERT to Mixture-of-Experts via Importance-Guided Adaptation](https://arxiv.org/pdf/2204.07675.pdf)
* [MATH Dataset](https://yach-doc-shimo.zhiyinlou.com/docs/ZzkLVnoKB4T4Vz3Q/)
* Leaderboard
1. [Open LLM Leaderboard - a Hugging Face Space by HuggingFaceH4](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)
2. [Alpaca Eval Leaderboard (tatsu-lab.github.io)](https://tatsu-lab.github.io/alpaca_eval/)
3. [Leaderboard | C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models (cevalbenchmark.com)](https://cevalbenchmark.com/static/model.html?method=ChatGLM2)
* Others
1. [Models - OpenAI API](https://platform.openai.com/docs/models/gpt-4)
